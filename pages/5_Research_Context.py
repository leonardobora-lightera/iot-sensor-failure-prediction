""""""

P√°gina 5: Contexto da Pesquisa - Descobertas e AprendizadosPage 5: Research Context - Project Background & Key Discoveries

Vers√£o PT-BR Acess√≠vel - Linguagem Simplificada para Stakeholders"""

"""import streamlit as st

import streamlit as stimport sys

import sysfrom pathlib import Path

from pathlib import Path

# Add project root to path

# Add project root to pathsys.path.append(str(Path(__file__).parent.parent))

sys.path.append(str(Path(__file__).parent.parent))

from utils.translations import get_text, get_language_from_session

# Header

st.title("üìñ Contexto da Pesquisa & Descobertas")# Get language

st.markdown("### Como desenvolvemos o modelo de predi√ß√£o de falhas e o que aprendemos no processo")lang = get_language_from_session(st.session_state)



st.markdown("---")# Header

st.title(get_text('research', 'title', lang))

# ===== SE√á√ÉO 1: O PROBLEMA =====st.markdown(f"### {get_text('research', 'subtitle', lang)}")

st.subheader("üéØ O Problema que Quer√≠amos Resolver")

st.markdown("---")

col1, col2 = st.columns([2, 1])

# Section 1: The Problem

with col1:st.subheader(get_text('research', 'problem_title', lang))

    st.markdown("""

    **Sensores IoT Falhando Sem Aviso Pr√©vio**col1, col2 = st.columns([2, 1])

    

    Imagine uma empresa com **789 sensores IoT** espalhados monitorando sistemas cr√≠ticos with col1:

    (temperatura, umidade, conectividade, etc.). Ao longo do tempo, **45 desses sensores     st.markdown("""

    falharam** (5.7% do total), causando:    **IoT Device Failures in Production Environments**

        

    - üö® **Paradas n√£o planejadas**: Sistemas param de funcionar sem aviso    Our organization deployed **789 IoT devices** for critical monitoring applications. 

    - üí∞ **Custo elevado**: Manuten√ß√£o emergencial custa 3-5x mais que preventiva    Over time, **45 devices (5.7%) exhibited critical failures** requiring emergency maintenance.

    - ‚è∞ **Tempo perdido**: Equipe t√©cnica precisa investigar 789 sensores para achar os 45 problem√°ticos    

    - üò∞ **Risco operacional**: Falhas podem afetar clientes e opera√ß√µes cr√≠ticas    **Challenges:**

        - üö® **Unplanned downtime** causes revenue loss and customer dissatisfaction

    **Nossa Miss√£o:**      - ‚öôÔ∏è **Emergency repairs** cost 3-5x more than preventive maintenance

    Criar um sistema que **preveja QUAIS sensores v√£o falhar ANTES de falharem**,     - üìä **No early warning system** - failures discovered reactively

    permitindo manuten√ß√£o preventiva e evitando custos emergenciais.    - üîç **Manual inspection** of 789 devices infeasible (resource constraints)

        

    Pense nisso como um "check-up m√©dico" para sensores - detectar problemas antes     **Business Objective:**

    de virarem emerg√™ncias! üè•    Build a machine learning model to **predict critical devices BEFORE failure** 

    """)    enabling **preventive maintenance** and **resource optimization**.

    """)

with col2:

    st.info("""with col2:

    **üìä N√∫meros do Projeto**    st.info("""

        **Impact Metrics**

    - **789** sensores no total    

    - **45** falharam (5.7%)    - **789** total devices

    - **744** funcionaram normalmente    - **45** critical failures (5.7%)

    - **29** caracter√≠sticas analisadas    - **16.8:1** imbalance ratio

    - **78.6%** taxa de detec√ß√£o    - **29** telemetry features

    - **0.8%** alarmes falsos    - **78.6%** recall achieved

    """)    - **84.6%** precision achieved

    """)

st.markdown("---")

st.markdown("---")

# ===== SE√á√ÉO 2: NOSSA SOLU√á√ÉO =====

st.subheader("üí° Como Resolvemos (Processo Simplificado)")# Section 2: Technical Approach

st.subheader("üî¨ Technical Approach & Pipeline")

st.markdown("""

Desenvolvemos uma solu√ß√£o em **3 passos principais**, usando Machine Learning st.markdown("""

(ensinar computador a reconhecer padr√µes):Our solution follows a **rigorous data science methodology** with emphasis on validation and avoiding data leakage.

""")""")



col1, col2, col3 = st.columns(3)# Pipeline diagram

col1, col2, col3 = st.columns(3)

with col1:

    st.markdown("""with col1:

    ### 1Ô∏è‚É£ Separar Dados    st.markdown("""

        **1Ô∏è‚É£ Data Preparation**

    **O que fizemos:**    

    - Dividimos os 789 sensores em dois grupos    - ‚úÖ **Stratified split** by device_id

    - **552 sensores** para "ensinar" o computador    - ‚úÖ **Zero overlap** (552 train, 237 test)

    - **237 sensores** para "testar" se aprendeu    - ‚úÖ **Balanced proportions** (5.6% vs 5.9% critical)

        - ‚ùå **Temporal split REJECTED** (data leakage)

    **Por que assim:**    """)

    - √â como estudar com 70% das quest√µes e fazer prova com 30% in√©ditas

    - Garante que modelo n√£o est√° "colando" - precisa realmente entender padr√µeswith col2:

    - Nenhum sensor aparece nos dois grupos (zero repeti√ß√£o)    st.markdown("""

        **2Ô∏è‚É£ Feature Engineering**

    **Desafio:**    

    - 45 falhas √© pouco (5.7% apenas)    - üìä **29 clean features** (telemetry + connectivity + messaging)

    - Precisamos dividir mantendo propor√ß√£o similar nos dois grupos    - ‚ö†Ô∏è **Leakage detection** (removed msg6_count, msg6_rate)

    - Usamos t√©cnica "estratificada" para garantir equil√≠brio    - üìà **Statistical analysis** (t-tests, distributions)

    """)    - üîó **Correlation study** (multicollinearity check)

    """)

with col2:

    st.markdown("""with col3:

    ### 2Ô∏è‚É£ Testar Algoritmos    st.markdown("""

        **3Ô∏è‚É£ Model Development**

    **O que fizemos:**    

    - Testamos 3 algoritmos diferentes (tipos de "c√©rebro" do computador)    - üéØ **SMOTE 0.5** (handle 16.8:1 imbalance)

    - **XGBoost**: Algoritmo popular, nossa refer√™ncia inicial    - ü§ñ **Algorithm comparison** (XGB, LGBM, CatBoost)

    - **LightGBM**: Algoritmo r√°pido, mas acertou menos    - üèÜ **CatBoost WINNER** (78.6% recall, 84.6% precision)

    - **CatBoost**: Algoritmo mais cuidadoso, VENCEDOR! üèÜ    - üì¶ **Production pipeline** (SimpleImputer ‚Üí SMOTE ‚Üí CatBoost)

        """)

    **Resultados:**

    - XGBoost: 71.4% de acerto (10 de 14 falhas detectadas)st.markdown("---")

    - LightGBM: 64.3% de acerto (9 de 14 falhas detectadas)

    - **CatBoost: 78.6% de acerto** (11 de 14 falhas detectadas)# Section 2.5: Why CatBoost?

    st.subheader("ü§ñ Why CatBoost? - Algorithm Explained")

    **Por que CatBoost ganhou:**

    - Aprende de forma mais "cuidadosa" (evita decorar padr√µes falsos)st.markdown("""

    - Funciona melhor com poucos dados (nosso caso - s√≥ 45 falhas)**CatBoost** (Categorical Boosting) is a gradient boosting algorithm developed by Yandex. 

    - Gerou menos alarmes falsos (2 vs 4 do XGBoost)We selected it over XGBoost and LightGBM based on rigorous comparison (see MODEL_COMPARISON.md).

    """)""")



with col3:col1, col2 = st.columns(2)

    st.markdown("""

    ### 3Ô∏è‚É£ Validar Rigorosamentewith col1:

        st.markdown("""

    **O que fizemos:**    **üîç What is CatBoost?**

    - Criamos **111 testes automatizados** para validar cada parte    

    - Garantimos que resultados s√£o **reproduz√≠veis** (sempre iguais)    CatBoost is an **advanced gradient boosting** algorithm that builds an ensemble of 

    - Documentamos **limita√ß√µes** (ser honesto sobre o que N√ÉO sabemos)    **decision trees sequentially**, where each tree corrects errors from previous trees.

        

    **Valida√ß√µes importantes:**    **Key Technical Advantages:**

    - ‚úÖ Modelo funciona em dados nunca vistos (237 sensores teste)    

    - ‚úÖ M√©tricas exatas confirmadas por script independente    1. **Ordered Boosting** üìä

    - ‚úÖ Sem "vazamento de informa√ß√£o" (dados teste n√£o influenciam treino)       - Prevents **target leakage** during training

    - ‚úÖ Performance est√°vel (n√£o varia entre execu√ß√µes)       - Reduces overfitting compared to XGBoost's level-wise approach

           - Uses different permutations to compute residuals

    **Resultado Final:**    

    - 78.6% das falhas detectadas antecipadamente    2. **Symmetric Trees** üå≥

    - Apenas 0.8% de alarmes falsos (2 em 237)       - Builds **balanced binary trees** (fewer leaves)

    - Modelo pronto para teste em produ√ß√£o üöÄ       - Faster prediction time in production

    """)       - Better generalization on unseen data

    

st.markdown("---")    3. **Native Categorical Support** üè∑Ô∏è

       - Handles categorical features WITHOUT one-hot encoding

# ===== SE√á√ÉO 3: DESCOBERTAS DO CAMINHO =====       - Computes optimal splits using target statistics

st.subheader("üîç Descobertas Importantes do Caminho")       - (Not used in this project - all features numerical)

    """)

st.markdown("""

Durante o desenvolvimento, fizemos **descobertas importantes** que mudaram nossa abordagem. with col2:

Cada erro foi uma oportunidade de aprender! Aqui est√£o os 4 principais aprendizados:    st.markdown("""

""")    **üèÜ Why CatBoost Won for This Project**

    

# Descoberta 1: Split Temporal Falhou    We compared 3 algorithms using identical SMOTE 0.5 preprocessing:

with st.expander("**üö® Descoberta 1: Tentar Dividir por Tempo Foi Um Desastre (0% de Acerto)**", expanded=False):    

    st.markdown("""    | Algorithm | Recall | Precision | F1 | False Alarms |

    #### O Que Tentamos Fazer    |-----------|--------|-----------|----|--------------| 

        | XGBoost   | 71.4%  | 71.4%     | 71.4% | 4/237 (1.7%) |

    Pensamos: "Vamos usar dados antigos para treinar e dados recentes para testar".     | LightGBM  | 64.3%  | 69.2%     | 66.7% | 4/237 (1.7%) |

    Parecia fazer sentido - como aprender hist√≥ria usando fatos passados para prever futuros!    | **CatBoost** | **78.6%** | **84.6%** | **81.5%** | **2/237 (0.8%)** |

        

    #### O Que Aconteceu    **CatBoost delivered:**

        - ‚úÖ **+7.2pp recall** vs XGBoost (1 more critical device detected)

    **Resultado: 0% de acerto!** üò±      - ‚úÖ **+13.2pp precision** vs XGBoost (50% fewer false alarms)

    O modelo n√£o detectou NENHUMA falha nos dados de teste. Total fracasso.    - ‚úÖ **Exceeds 80% precision target** (business requirement)

        - ‚úÖ **21.4% miss rate** vs 28.6% XGBoost (better risk reduction)

    #### Por Que Falhou (Descoberta T√©cnica)    

        **Business Impact:**

    **Problema:** Nossos dados n√£o s√£o uma "linha do tempo" - s√£o uma **foto final**.    - 11/14 critical devices detected (vs 10/14 XGBoost)

        - Only 2 false alarms in 237 devices (vs 4 XGBoost)

    Imagine assim:    - Optimized investigation workload

    - Cada sensor tem **1 linha** juntando TODOS os meses de opera√ß√£o    

    - √â como tirar foto de algu√©m aos 30 anos e tentar adivinhar como era aos 10    **Technical Insight:**

    - Dados "antigos" e "recentes" s√£o na verdade **o mesmo sensor em momentos diferentes**    CatBoost's **ordered boosting** likely performed better due to our 

    - 650 sensores apareceram nos DOIS grupos (treino E teste) - vazamento massivo!    **small critical sample size** (31 training critical devices). The algorithm's 

        built-in overfitting protection proved crucial for this imbalanced dataset.

    **Analogia:**    """)

    > √â como estudar quest√µes de uma prova e depois fazer a MESMA prova pensando 

    > que √© diferente. √ìbvio que voc√™ vai gabaritar... mas n√£o aprendeu nada de verdade!st.markdown("---")

    

    #### O Que Aprendemos# Section 3: Key Discoveries & Lessons Learned

    st.subheader("üí° Key Discoveries & Critical Lessons")

    ‚úÖ **Li√ß√£o:** Dividir por tempo s√≥ funciona com dados tipo "s√©rie temporal" (1 linha = 1 momento)  

    ‚úÖ **Solu√ß√£o:** Dividimos por SENSOR (cada sensor aparece EM UM grupo s√≥)  # Discovery 1: Temporal Split Failure

    ‚úÖ **Impacto:** Performance caiu de 0% (inv√°lido) para 50% (honesto) - come√ßamos do zero realwith st.expander("**üö® Discovery 1: Temporal Split Failed (0% Recall)**", expanded=True):

        st.markdown("""

    **Documenta√ß√£o:** Ver CHANGELOG.md Phase 2 para an√°lise completa do erro    **Problem:** Initial approach split data by time (old messages ‚Üí train, recent ‚Üí test)

    """)    

    **Result:** Model achieved **0% recall** - couldn't detect ANY critical devices!

# Descoberta 2: Data Leakage MSG6    

with st.expander("**üîç Descoberta 2: Achamos Uma 'Cola' nos Dados e Removemos**", expanded=False):    **Root Cause Analysis:**

    st.markdown("""    - Dataset was **aggregated** (1 row per device, not time-series)

    #### O Que Encontramos    - Temporal split created **650 devices in BOTH train and test** (severe leakage)

        - Model memorized device IDs instead of learning patterns

    Nosso modelo estava com **87.5% de precis√£o** - parecia incr√≠vel! üéâ      - Critical devices appeared in training data, test became "easy memorization"

    Mas investigamos e descobrimos que estava "colando na prova"...    

        **Lesson Learned:** 

    #### A "Cola" (Data Leakage)    > ‚ö†Ô∏è **Always validate split assumptions** - temporal split only valid for true time-series data

        > 

    Havia duas caracter√≠sticas suspeitas nos dados:    > ‚úÖ **Stratified split by device_id** ensures zero overlap and honest evaluation

    - `msg6_count`: Quantidade de mensagens tipo 6 enviadas    

    - `msg6_rate`: Taxa de mensagens tipo 6    **Impact:** Switching to stratified split ‚Üí **50% recall baseline** (honest performance)

        """)

    **Descoberta chocante:**  

    Mensagem tipo 6 significa **"Sensor reportando status cr√≠tico"**! üò±# Discovery 2: MSG6 Leakage

    with st.expander("**üîç Discovery 2: Data Leakage from msg6_count Feature**", expanded=False):

    **O problema:**    st.markdown("""

    > √â como perguntar "Este aluno vai reprovar?" e uma das informa√ß√µes dispon√≠veis     **Problem:** Model with `msg6_count` feature achieved suspicious **87.5% precision**

    > √© "Quantidade de vezes que disse 'estou reprovando'". √ìbvio que √© a resposta disfar√ßada!    

        **Investigation:** Analyzed feature importance and distributions

    **Prova do vazamento:**    

    - Feature `msg6_count` foi a **#1 mais importante** (31% do modelo)    **Finding:**

    - Sensores cr√≠ticos: SEMPRE enviam msg6    - `msg6_count` was **#1 feature** (31% importance - red flag!)

    - Sensores normais: NUNCA enviam msg6    - Message type 6 = **"Device Critical Status Report"**

    - Correla√ß√£o 100% com resposta - isso √© "colar", n√£o "prever"    - Critical devices send MORE msg6 messages by definition

        - Feature contains **ground truth label information** (data leakage)

    #### O Que Fizemos    

        **Action Taken:**

    1. ‚ùå **Removemos** `msg6_count` e `msg6_rate` completamente    - ‚ùå Removed `msg6_count` and `msg6_rate` from feature set

    2. ‚úÖ **Re-treinamos** modelo com apenas 29 features "honestas"    - ‚úÖ Re-trained model with 29 clean features only

    3. ‚úÖ **Performance caiu** de 87.5% para 50% (esperado - agora √© real)    - ‚úÖ Performance dropped to 50% recall (expected with honest features)

        

    #### O Que Aprendemos    **Lesson Learned:**

        > ‚ö†Ô∏è **High single-feature importance = potential leakage indicator**

    ‚ö†Ô∏è **Li√ß√£o:** Performance MUITO alta pode ser sinal de problema, n√£o sucesso!      > 

    ‚úÖ **Sempre perguntar:** "Esta informa√ß√£o estaria dispon√≠vel ANTES da falha?"      > ‚úÖ **Domain knowledge critical** - understand what features MEAN in business context

    ‚úÖ **Entender dom√≠nio:** Saber o que features significam salva de armadilhas    > 

        > ‚úÖ **Validate feature distributions** between critical and normal groups

    **Analogia Final:**    

    > Preferimos modelo com 78.6% HONESTO do que 95% "colando".     **Impact:** Honest baseline established ‚Üí enabled real optimization work

    > Um m√©dico que acerta 80% dos diagn√≥sticos √© melhor que um que acerta 100%     """)

    > lendo o resultado do exame! üè•

    """)# Discovery 3: Synthetic Data Validation

with st.expander("**üß™ Discovery 3: Theoretical vs Empirical Synthetic Data**", expanded=False):

# Descoberta 3: CatBoost Venceu    st.markdown("""

with st.expander("**üèÜ Descoberta 3: CatBoost Foi 7% Melhor Que XGBoost**", expanded=False):    **Experiment:** Validate model using synthetic critical devices

    st.markdown("""    

    #### Compara√ß√£o de Algoritmos (Teste Cego)    **Approach 1 - Theoretical (NB06):**

        - **Assumption:** "High values = critical" (e.g., p75-p100 percentiles)

    Testamos 3 algoritmos diferentes usando os MESMOS dados para ser justo:    - **Method:** Sample from upper quartiles of general distribution

        - **Result:** 0% recall - TOTAL FAILURE ‚ùå

    | Algoritmo | Falhas Detectadas | Alarmes Falsos | Decis√£o |    

    |-----------|-------------------|----------------|---------|    **Approach 2 - Empirical (NB06B):**

    | XGBoost   | 10/14 (71.4%)     | 4/237 (1.7%)   | ü•à Baseline |    - **Validation:** Analyzed critical vs normal distributions FIRST

    | LightGBM  | 9/14 (64.3%)      | 4/237 (1.7%)   | ‚ùå Descartado |    - **Discovery:** Direction varies by feature (battery LOW, temp HIGH, messages VARIABLE)

    | **CatBoost** | **11/14 (78.6%)** | **2/237 (0.8%)** | üèÜ **VENCEDOR** |    - **Method:** SMOTE interpolation from REAL critical devices (preserves correlations)

        - **Result:** 100% recall - validates SMOTE works ‚úÖ

    #### Por Que CatBoost Ganhou    

        **Lesson Learned:**

    **1. Detectou MAIS falhas** (+1 sensor vs XGBoost)    > ‚ö†Ô∏è **Theoretical assumptions fail** - "high values = bad" is not universal

    - XGBoost: 10 de 14 cr√≠ticos detectados    > 

    - CatBoost: 11 de 14 cr√≠ticos detectados    > ‚úÖ **Empirical analysis required** - test statistical differences before sampling

    - **+7.2 pontos percentuais** de melhoria    > 

        > ‚úÖ **SMOTE preserves patterns** - interpolates within real distribution manifold

    **2. Gerou MENOS alarmes falsos** (metade!)    

    - XGBoost: 4 investiga√ß√µes desnecess√°rias    **Important Caveat:**

    - CatBoost: 2 investiga√ß√µes desnecess√°rias    - 100% synthetic recall does NOT mean model is better than 78.6% real recall

    - **50% de redu√ß√£o** em trabalho desperdi√ßado    - Synthetic generated FROM training critical ‚Üí model KNOWS these patterns

        - Real test set (78.6%) remains **authoritative validation**

    **3. Funciona melhor com poucos dados**    - Synthetic useful for **stress testing edge cases**, not independent validation

    - CatBoost aprende de forma mais "cautelosa"    """)

    - Evita "decorar" padr√µes que s√£o coincid√™ncia

    - Ideal para nosso caso (s√≥ 45 falhas para aprender)# Discovery 4: Algorithm Comparison

    with st.expander("**‚öñÔ∏è Discovery 4: CatBoost Outperforms XGBoost and LightGBM**", expanded=False):

    #### Explica√ß√£o Simples: Como Funciona?    st.markdown("""

        **Experiment:** Compare 3 gradient boosting algorithms with SMOTE 0.5

    **Analogia do M√©dico:**    

        **Results:**

    Imagine 3 m√©dicos diagnosticando doen√ßas:    

        | Model | Recall | Precision | F1-Score | AUC | Decision |

    - **LightGBM:** M√©dico apressado - r√°pido mas erra muito    |-------|--------|-----------|----------|-----|----------|

    - **XGBoost:** M√©dico experiente - bom mas √†s vezes confia demais em 1 sintoma    | XGBoost + SMOTE | 71.4% | 71.4% | 71.4% | 0.8799 | Baseline |

    - **CatBoost:** M√©dico meticuloso - analisa TODOS sintomas com cuidado    | LightGBM + SMOTE | 64.3% | 69.2% | 66.7% | 0.8823 | ‚ùå DISQUALIFIED (recall < 70%) |

        | **CatBoost + SMOTE** | **78.6%** | **84.6%** | **81.5%** | **0.8621** | ‚úÖ **WINNER** |

    CatBoost √© o "m√©dico meticuloso" - demora um pouco mais mas acerta mais!    

        **Why CatBoost Won:**

    #### Impacto Real    - ‚úÖ **+7.2 pp recall improvement** (10/14 ‚Üí 11/14 critical detected)

        - ‚úÖ **+13.2 pp precision improvement** (71.4% ‚Üí 84.6%, only 2 false alarms)

    Em 1000 sensores hipot√©ticos:    - ‚úÖ **Ordered boosting** reduces overfitting on small dataset (789 total, 45 critical)

    - **CatBoost:** 47 falhas evitadas, 8 alarmes falsos    - ‚úÖ **Symmetric trees** provide better generalization vs XGBoost asymmetric

    - **XGBoost:** 42 falhas evitadas, 16 alarmes falsos    

        **Lesson Learned:**

    **Ganho:** +5 sensores salvos + metade do trabalho desperdi√ßado! üí∞    > ‚úÖ **Test multiple algorithms** - different inductive biases work better on different data

        > 

    **Documenta√ß√£o:** Ver MODEL_COMPARISON.md para an√°lise t√©cnica completa    > ‚úÖ **CatBoost excels on small datasets** - default regularization prevents overfitting

    """)    > 

    > ‚ö†Ô∏è **Tradeoff exists** - CatBoost slightly lower AUC but MUCH better precision/recall

# Descoberta 4: Limita√ß√£o Temporal (NOVA!)    

with st.expander("**‚ö†Ô∏è Descoberta 4: Dataset Tem Problema Temporal (Limita√ß√£o Cr√≠tica)**", expanded=True):    **See MODEL_COMPARISON.md** for complete analysis with confusion matrices and business impact.

    st.markdown("""    """)

    #### O Problema Temporal Descoberto

    st.markdown("---")

    Durante valida√ß√£o final da POC, identificamos uma **limita√ß√£o metodol√≥gica cr√≠tica** 

    que afeta a interpreta√ß√£o dos resultados.# Section 4: Features Engineering Deep Dive

    st.subheader("üîß Features Engineering: 29 Features Explained")

    **Problema:** Cada sensor tem **1 linha** agregando **TODO o per√≠odo operacional**.

    st.markdown("""

    #### Entendendo a Limita√ß√£o (Analogia Simples)Our final model uses **29 numerical features** extracted from IoT device telemetry, grouped into 3 categories:

    """)

    Imagine que voc√™ quer prever se uma crian√ßa vai ter problemas de sa√∫de aos 18 anos.

    tab1, tab2, tab3 = st.tabs(["üì° Telemetry (18)", "üì∂ Connectivity (9)", "üì® Messaging (2)"])

    **Dataset ideal (s√©rie temporal):**

    - Linha 1: Peso aos 5 anoswith tab1:

    - Linha 2: Peso aos 10 anos    st.markdown("""

    - Linha 3: Peso aos 15 anos    ### Telemetry Features (18 total)

    - Linha 4: Peso aos 18 anos (resultado)    

        **Optical Sensor (7 features):**

    **Nosso dataset (agregado):**    - `optical_mean`, `optical_std`, `optical_min`, `optical_max` - Central tendency and spread

    - Linha √∫nica: Peso m√©dio dos 5 aos 18 anos + resultado aos 18    - `optical_readings` - Sample count (data quality indicator)

        - `optical_below_threshold` - Degradation indicator

    **Consequ√™ncia:**      - `optical_range` - Variability metric

    > N√£o conseguimos distinguir se "peso alto" ocorreu ANTES (causa) ou     

    > JUNTO com problema (coincid√™ncia). Tudo est√° misturado!    **Temperature Sensor (6 features):**

        - `temp_mean`, `temp_std`, `temp_min`, `temp_max` - Thermal distribution

    #### O Problema em 3 Fases (Lifecycle)    - `temp_above_threshold` - Overheating indicator

        - `temp_range` - Thermal stability

    Sensores passam por 3 fases de vida:    

        **Battery/Power (5 features):**

    1. **üî¨ Lab:** Testados em laborat√≥rio (ambiente controlado)    - `battery_mean`, `battery_std`, `battery_min`, `battery_max` - Voltage distribution

    2. **üí§ Inactive:** Guardados esperando instala√ß√£o (sem uso)    - `battery_below_threshold` - Low power events

    3. **üè≠ Production:** Operando em campo (ambiente real)    

        **Engineering Rationale:**

    **Nossos dados misturam tudo:**    - **Aggregations** capture both average behavior (mean) and variability (std, range)

    - Temperatura m√©dia = m√©dia Lab + Inactive + Production    - **Thresholds** encode domain knowledge (e.g., battery < 3.0V = critical)

    - Conectividade = mistura de 3 ambientes diferentes    - **Min/Max** detect extreme events (spikes, drops)

    - N√£o sabemos QUANDO padr√£o aconteceu    

        **Key Insight:** Critical devices show **LOW battery** (power failure), **HIGH temp** (overheating), 

    **Exemplo Real:**    **VARIABLE optical** (unstable sensor) - NOT universally "high values".

    > Sensor tem "temperatura alta" nos dados. Mas isso foi:    """)

    > - Em Lab (teste de estresse - normal) ‚úÖ

    > - Ou em Production (superaquecimento - problema) ‚ùåwith tab2:

    >     st.markdown("""

    > Imposs√≠vel separar! Dados agregados n√£o t√™m informa√ß√£o temporal.    ### Connectivity Features (9 total)

        

    #### O Que Isso Significa Para o Modelo    **Signal-to-Noise Ratio - SNR (3 features):**

        - `snr_mean`, `snr_std`, `snr_min` - Signal quality distribution

    **Modelo detecta CORRELA√á√ÉO, n√£o prova CAUSA:**    - **Importance:** Low SNR indicates poor signal ‚Üí communication failures

        

    ‚úÖ **O que podemos dizer:**    **Reference Signal Received Power - RSRP (3 features):**

    - "Sensores com padr√£o X t√™m 78.6% chance de falhar"    - `rsrp_mean`, `rsrp_std`, `rsrp_min` - Signal strength distribution

    - "Modelo identifica 11/14 sensores problem√°ticos"    - **Importance:** Weak signal (< -110 dBm) ‚Üí device struggling to connect

    - "√ötil para priorizar inspe√ß√µes"    

        **Reference Signal Received Quality - RSRQ (3 features):**

    ‚ùå **O que N√ÉO podemos dizer:**    - `rsrq_mean`, `rsrq_std`, `rsrq_min` - Link quality distribution

    - "Padr√£o X CAUSA falha" (pode ser coincid√™ncia temporal)    - **Importance:** Poor quality ‚Üí retransmissions, latency, eventual dropout

    - "Padr√£o X ocorreu ANTES da falha" (pode ter sido simult√¢neo)    

    - "Modelo prev√™ o FUTURO" (pode estar detectando o PRESENTE)    **Engineering Rationale:**

        - **Mean values** show average connectivity health

    #### Por Que Isso √â IMPORTANTE    - **Std/variability** indicates connection stability (stable vs flaky)

        - **Min values** detect worst-case scenarios (connection almost lost)

    **Cen√°rio de risco:**    

    - Empresa pode implementar modelo achando que est√° "prevendo futuro"    **Key Insight:** Critical devices show **degrading connectivity BEFORE complete failure** 

    - Na verdade pode estar apenas "detectando presente"    (SNR dropping, RSRP weakening, RSRQ unstable) - early warning signal!

    - Sensor j√° pode ter falhado quando modelo alerta    """)

    

    **Analogia:**with tab3:

    > √â como "prever" que algu√©m est√° doente medindo febre.     st.markdown("""

    > Tecnicamente funciona... mas febre J√Å √â a doen√ßa, n√£o previs√£o dela!    ### Messaging Features (2 total)

        

    #### Como Mitigamos (Consci√™ncia Cient√≠fica)    **`total_messages` (count):**

        - Total number of messages sent by device in observation window

    Implementamos 3 estrat√©gias para lidar com limita√ß√£o:    - **Low values:** Silent device (already failed or communication blocked)

        - **Normal values:** Regular telemetry reporting (healthy)

    **1. üìä Drift Monitoring (Monitoramento de Mudan√ßas)**    - **High values:** Possible "death throes" (device spamming before failure)

    - Detecta quando dados novos s√£o diferentes dos antigos    

    - Usa teste estat√≠stico (KS test) em 29 caracter√≠sticas    **`max_frame_count` (integer):**

    - Alerta se modelo est√° "desaprendendo" (dados mudaram)    - Maximum frame count observed in message fragmentation

    - **Script:** `scripts/drift_monitor.py`    - **High values:** Device attempting **desperate reconnection** (communication stress)

        - **Importance:** #1 or #2 most important feature across all models

    **2. üß™ A/B Testing (Teste em Produ√ß√£o)**    - **Interpretation:** When device struggles, it fragments messages more (retries, errors)

    - Guia completo para validar modelo empiricamente    

    - 4 fases: Shadow ‚Üí Controlled ‚Üí Monitoring ‚Üí Full Deploy    **Engineering Rationale:**

    - Compara sensores COM predi√ß√£o vs SEM predi√ß√£o    - **Activity level** (total_messages) separates silent failures from active devices

    - **Documento:** `docs/AB_TESTING_GUIDE.md` (950 linhas)    - **Fragmentation stress** (max_frame_count) detects communication desperation

        

    **3. üîÆ Feature Engineering Temporal (Futuro)**    **Key Insight:** `max_frame_count` is a **communication stress indicator** - 

    - Roadmap para coletar dados time-series (m√∫ltiplas linhas/sensor)    critical devices show abnormally high frame counts as they struggle to maintain connection.

    - Rolling windows (janelas de 7 dias, 30 dias)    

    - Tend√™ncias temporais (aumentando vs diminuindo)    **Why only 2 messaging features?**

    - **Documento:** `docs/FEATURE_ENGINEERING_TEMPORAL.md` (850 linhas)    - Originally had `msg6_count`, `msg6_rate` ‚Üí **REMOVED due to data leakage**

        - Message type 6 = "Critical Status Report" ‚Üí contains ground truth label info

    #### Nossa Postura (Transpar√™ncia > Ocultar)    - Keeping only neutral messaging metrics (total volume, fragmentation) ensures honest prediction

        """)

    **Por que documentamos limita√ß√£o:**

    1. ‚úÖ **Honestidade cient√≠fica** - reconhecer o que n√£o sabemosst.markdown("---")

    2. ‚úÖ **Gerenciar expectativas** - stakeholders entendem escopo

    3. ‚úÖ **Planejar mitiga√ß√£o** - roadmap claro para melhorar# Section 5: Validation Philosophy

    4. ‚úÖ **Evitar surpresas** - produ√ß√£o validar√° empiricamentest.subheader("‚úÖ Validation Philosophy & Best Practices")

    

    **Frase-chave:**col1, col2 = st.columns(2)

    > "Consci√™ncia das limita√ß√µes √© FOR√áA, n√£o fraqueza. Modelo com 78.6% honesto 

    > e transparente √© melhor que modelo com 95% com assumptions escondidas."with col1:

        st.markdown("""

    **Documenta√ß√£o Completa:** Ver `docs/TEMPORAL_LIMITATIONS.md` (1000 linhas)     **What We Did RIGHT ‚úÖ**

    para an√°lise t√©cnica detalhada das limita√ß√µes metodol√≥gicas.    

    """)    1. **Stratified Split by Device ID**

       - Zero overlap between train (552) and test (237)

st.markdown("---")       - Balanced proportions (5.6% vs 5.9% critical)

       - Honest evaluation on unseen devices

# ===== SE√á√ÉO 4: LIMITA√á√ïES CONHECIDAS (NOVA SE√á√ÉO) =====    

st.subheader("‚ö†Ô∏è Limita√ß√µes Conhecidas (Transpar√™ncia Cient√≠fica)")    2. **Leakage Detection & Removal**

       - Analyzed feature importance distributions

st.markdown("""       - Removed msg6_count/msg6_rate (ground truth leak)

**Ser honesto sobre o que N√ÉO sabemos √© t√£o importante quanto demonstrar o que sabemos.**       - Validated with domain experts

    

Esta se√ß√£o documenta as **limita√ß√µes metodol√≥gicas** identificadas durante a POC.     3. **Empirical Validation Over Theory**

Reconhecer limita√ß√µes √© sinal de **maturidade cient√≠fica**, n√£o fraqueza.       - Tested synthetic data assumptions (NB06 failure)

""")       - Corrected with empirical analysis (NB06B success)

       - Statistical tests before engineering features

col1, col2 = st.columns(2)    

    4. **Multiple Algorithm Comparison**

with col1:       - XGBoost, LightGBM, CatBoost tested

    st.markdown("""       - Decision matrix with business criteria

    ### üî¥ Limita√ß√£o 1: Impossibilidade Causal Temporal       - Documented tradeoffs (MODEL_COMPARISON.md)

        

    **Problema:**    5. **Production-Ready Pipeline**

    - Dataset = 1 linha/sensor agregando todo hist√≥rico       - End-to-end Pipeline (Imputer ‚Üí SMOTE ‚Üí CatBoost)

    - N√£o sabemos QUANDO padr√µes ocorreram       - Saved artifacts (joblib + metadata JSON)

    - Lab + Inactive + Production misturados       - Inference functions for batch/single prediction

        """)

    **Consequ√™ncia:**

    - Modelo detecta **correla√ß√£o**, n√£o **causa**with col2:

    - N√£o podemos provar que padr√£o veio ANTES de falha    st.markdown("""

    - Pode estar detectando problema J√Å existente    **Lessons for Future Projects ‚ö†Ô∏è**

        

    **Analogia:**    1. **Split Validation**

    > M√©dico vendo raio-X de corpo inteiro de vida toda.        - ‚ùå Don't assume temporal split works for aggregated data

    > Consegue ver problema, mas n√£o sabe se foi aos 5 ou 50 anos.       - ‚úÖ Validate overlap between train/test BEFORE modeling

           - ‚úÖ Use stratification for imbalanced classes

    **Mitiga√ß√£o:**    

    - ‚úÖ Drift monitoring detecta mudan√ßas dados    2. **Feature Leakage**

    - ‚úÖ A/B testing validar√° empiricamente produ√ß√£o       - ‚ùå Don't trust high single-feature importance blindly

    - ‚úÖ Roadmap feature engineering temporal       - ‚úÖ Understand what features MEAN in business context

           - ‚úÖ Check if feature contains "future information"

    ---    

        3. **Theoretical Assumptions**

    ### üü° Limita√ß√£o 2: Lifecycle Confounding       - ‚ùå Don't assume "high = bad" or "low = good"

           - ‚úÖ Analyze distributions empirically FIRST

    **Problema:**       - ‚úÖ Use statistical tests (t-test, Mann-Whitney)

    - Sensores passam Lab ‚Üí Inactive ‚Üí Production    

    - Features agregam fases com comportamentos diferentes    4. **Synthetic Validation**

    - Padr√µes organizacionais podem criar artifacts       - ‚ùå Don't use synthetic as independent validation

           - ‚úÖ Understand synthetic = interpolation of training

    **Exemplo:**       - ‚úÖ Use real held-out test set as authoritative

    - Sensor temperatura alta: teste Lab ou falha Production?    

    - Sensor sem mensagens: armazenado Inactive ou quebrado?    5. **Documentation**

    - Conectividade ruim: laborat√≥rio sem rede ou campo sem sinal?       - ‚úÖ Document decisions (why CatBoost vs XGBoost?)

           - ‚úÖ Keep history of failed approaches (learning value)

    **Consequ√™ncia:**       - ‚úÖ Create artifacts for stakeholders (MODEL_COMPARISON.md)

    - Dif√≠cil separar comportamento normal vs anormal    """)

    - Deployment patterns podem influenciar modelo

    st.markdown("---")

    **Mitiga√ß√£o:**

    - ‚úÖ Documentado em TEMPORAL_LIMITATIONS.md# Section 6: Business Impact Summary

    - ‚úÖ Valida√ß√£o produ√ß√£o comparar√° sensores similaresst.subheader("üíº Business Impact & ROI")

    - ‚úÖ Futuro: separar fases lifecycle em features distintas

    """)col1, col2, col3 = st.columns(3)



with col2:with col1:

    st.markdown("""    st.metric(

    ### üü¢ Limita√ß√£o 3: Amostra Pequena Classe Cr√≠tica        "Critical Devices Detected",

            "11/14",

    **Problema:**        delta="78.6% coverage",

    - Apenas 45 sensores cr√≠ticos no total        help="Preventive maintenance triggered for 11 critical devices"

    - 31 para treino, 14 para teste    )

    - Dif√≠cil generalizar com poucos exemplos    st.caption("**Prevented failures** before emergency breakdown")

    

    **Consequ√™ncia:**with col2:

    - Modelo pode n√£o capturar TODOS tipos de falha    st.metric(

    - 3 falhas n√£o detectadas (21.4% miss rate)        "False Alarms",

    - Novos modos de falha podem aparecer produ√ß√£o        "2/237",

            delta="0.8% FP rate",

    **Por que aceit√°vel:**        delta_color="inverse",

    - ‚úÖ 78.6% coverage j√° √© grande melhoria vs 0% (reativo)        help="Only 2 false positives in entire normal population"

    - ‚úÖ Miss rate 21.4% aceit√°vel para POC    )

    - ‚úÖ Modelo evolui com mais dados produ√ß√£o    st.caption("**Minimal investigation overhead** for operations team")

    

    **Mitiga√ß√£o:**with col3:

    - ‚úÖ Continuar coletando dados produ√ß√£o    st.metric(

    - ‚úÖ Re-treinar modelo periodicamente        "Missed Failures",

    - ‚úÖ Meta m√©dio prazo: 85-90% recall        "3/14",

            delta="21.4% miss rate",

    ---        delta_color="inverse",

            help="3 critical devices not detected (acceptable tradeoff)"

    ### üîµ Limita√ß√£o 4: Valida√ß√£o POC vs Produ√ß√£o    )

        st.caption("**Fallback:** Manual inspection + domain expertise")

    **Status Atual: POC (Proof of Concept)**

    st.markdown("""

    **O que validamos:****Scenario: 1000 Devices Deployed**

    - ‚úÖ Viabilidade t√©cnica (78.6% recall poss√≠vel)

    - ‚úÖ Reproducibilidade (scripts/reproduce_results.py)- ‚úÖ **47 failures prevented** vs 42 without model (+5 devices saved)

    - ‚úÖ Rigor metodol√≥gico (111/114 testes passing)- ‚úÖ **12 emergency repairs** vs 17 without model (-5 urgent calls)

    - ‚úÖ **8 false alarms** vs 16 with baseline model (-50% investigation cost)

    **O que N√ÉO validamos ainda:**- üí∞ **Estimated savings:** $25K-$50K per year (reduced downtime + optimized maintenance)

    - ‚è≥ Performance em dados produ√ß√£o real (A/B test pendente)

    - ‚è≥ Lat√™ncia <50ms para 1000 devices/sec**Model enables proactive maintenance strategy** shifting from reactive firefighting to planned interventions.

    - ‚è≥ Robustez edge cases (CSV malformado, NaN 100%)""")

    

    **Roadmap Produ√ß√£o (3-4 semanas):**st.markdown("---")

    1. Performance testing carga

    2. Hardening resilience (retry logic, circuit breakers)# Footer

    3. Audit trail completo (rastreabilidade)st.info("""

    4. Model registry m√∫ltiplas vers√µes + rollbacküìö **Further Reading:**

    - **MODEL_COMPARISON.md** - Complete algorithm comparison with confusion matrices

    **Postura:**- **Notebooks 02B-08** - Detailed technical implementation and validation

    > Esta √© uma POC validando IDEIA, n√£o produto final pronto. - **CHANGELOG.md** - Complete project timeline (12 phases)

    > Sabemos gaps e temos plano claro para endere√ßar.""")

    """)

st.caption("""

st.info("""**Research Context** | IoT Predictive Maintenance Project | CatBoost v1.0 | November 2025

üí° **Por que documentar limita√ß√µes?**""")


1. **Gerenciar expectativas:** Stakeholders sabem o que esperar do modelo
2. **Planejar evolu√ß√£o:** Roadmap claro para melhorias futuras  
3. **Evitar surpresas:** Produ√ß√£o j√° sabe desafios potenciais
4. **Demonstrar maturidade:** Consci√™ncia cient√≠fica > ocultar problemas

**Frase-chave:** "Transpar√™ncia sobre limita√ß√µes gera mais confian√ßa que promessas irrealistas."
""")

st.markdown("---")

# ===== SE√á√ÉO 5: IMPACTO REAL =====
st.subheader("üíº Impacto Real no Neg√≥cio")

st.markdown("""
**Traduzindo m√©tricas t√©cnicas para valor business:**  
De cada 100 sensores cr√≠ticos, conseguimos detectar 79 ANTES de falharem!
""")

col1, col2, col3 = st.columns(3)

with col1:
    st.metric(
        "Falhas Detectadas",
        "11/14",
        delta="78.6% cobertura",
        help="11 sensores cr√≠ticos detectados antecipadamente de 14 totais"
    )
    st.caption("**Manuten√ß√£o preventiva** programada antes de quebrar")

with col2:
    st.metric(
        "Alarmes Falsos",
        "2/237",
        delta="0.8% taxa FP",
        delta_color="inverse",
        help="Apenas 2 investiga√ß√µes desnecess√°rias em 237 sensores normais"
    )
    st.caption("**Overhead m√≠nimo** para equipe operacional")

with col3:
    st.metric(
        "Falhas N√£o Detectadas",
        "3/14",
        delta="21.4% miss rate",
        delta_color="inverse",
        help="3 sensores cr√≠ticos que modelo n√£o previu"
    )
    st.caption("**Fallback:** Inspe√ß√£o manual + expertise dom√≠nio")

st.markdown("---")

# Cen√°rio Hipot√©tico
st.markdown("""
### üìà Cen√°rio Hipot√©tico: 1000 Sensores Implantados

**Assumindo mesma propor√ß√£o 5.7% falhas (57 sensores cr√≠ticos):**

| M√©trica | Sem Modelo (Reativo) | Com Modelo (Preditivo) | Melhoria |
|---------|---------------------|------------------------|----------|
| **Falhas Detectadas Antecipadamente** | 0 (0%) | 45 (78.6%) | +45 sensores |
| **Manuten√ß√µes Emergenciais** | 57 (100%) | 12 (21.4%) | -45 emerg√™ncias |
| **Investiga√ß√µes Desnecess√°rias** | N/A | 8 (0.8% de 943) | 8 inspe√ß√µes |
| **Sensores Salvos vs Baseline XGBoost** | N/A | +5 vs XGBoost | +5 sensores |

**üí∞ Estimativa de Economia Anual:**

- **Custo manuten√ß√£o emergencial:** R$ 5.000 por sensor
- **Custo manuten√ß√£o preventiva:** R$ 1.500 por sensor
- **Economia por sensor:** R$ 3.500

**C√°lculo:**
- 45 sensores: manuten√ß√£o preventiva (R$ 1.500) vs emergencial (R$ 5.000)
- **45 √ó R$ 3.500 = R$ 157.500 economizados/ano** üí∞
- Mais: redu√ß√£o downtime, satisfa√ß√£o cliente, produtividade equipe

**Custo investiga√ß√µes falsas:**
- 8 investiga√ß√µes √ó R$ 500 = R$ 4.000
- **ROI l√≠quido: R$ 153.500/ano** (39x retorno)

---

**Importante:** N√∫meros s√£o estimativas baseadas em test set 237 sensores. 
Valida√ß√£o em produ√ß√£o (A/B testing) confirmar√° performance real.
""")

st.markdown("---")

# ===== SE√á√ÉO 6: VALIDA√á√ÉO E RIGOR =====
st.subheader("‚úÖ Valida√ß√£o & Rigor Cient√≠fico")

st.markdown("""
**Como garantimos que resultados s√£o confi√°veis:**
""")

col1, col2 = st.columns(2)

with col1:
    st.markdown("""
    ### ‚úÖ O Que Fizemos Certo
    
    **1. Split Estratificado por Sensor**
    - ‚úÖ Zero overlap treino/teste (552 vs 237)
    - ‚úÖ Propor√ß√µes balanceadas (5.6% vs 5.9% cr√≠ticos)
    - ‚úÖ Avalia√ß√£o honesta em sensores nunca vistos
    
    **2. Detec√ß√£o e Remo√ß√£o Leakage**
    - ‚úÖ Analisamos import√¢ncia features
    - ‚úÖ Removemos msg6_count/msg6_rate (vazamento)
    - ‚úÖ Validamos com expertise dom√≠nio
    
    **3. Valida√ß√£o Emp√≠rica > Te√≥rica**
    - ‚úÖ Testamos assumptions com dados reais
    - ‚úÖ Corrigimos quando teoria falhou (NB06)
    - ‚úÖ Testes estat√≠sticos antes engineering
    
    **4. Compara√ß√£o M√∫ltiplos Algoritmos**
    - ‚úÖ XGBoost, LightGBM, CatBoost testados
    - ‚úÖ Crit√©rios business definidos (recall > precision)
    - ‚úÖ Tradeoffs documentados (MODEL_COMPARISON.md)
    
    **5. Reproducibilidade Validada**
    - ‚úÖ Script standalone confirma m√©tricas exatas
    - ‚úÖ 111/114 testes automatizados (97.4% passing)
    - ‚úÖ Random seed fixo (determinismo)
    - ‚úÖ `scripts/reproduce_results.py` prova cient√≠fica
    """)

with col2:
    st.markdown("""
    ### üìö Li√ß√µes Para Futuros Projetos
    
    **1. Valida√ß√£o de Split**
    - ‚ö†Ô∏è Sempre verificar overlap treino/teste
    - ‚ö†Ô∏è Split temporal s√≥ para s√©ries temporais reais
    - ‚úÖ Estratifica√ß√£o mant√©m balanceamento classes
    
    **2. Feature Leakage**
    - ‚ö†Ô∏è Alta import√¢ncia 1 feature = red flag
    - ‚ö†Ô∏è Entender significado business de features
    - ‚úÖ Perguntar: "Info dispon√≠vel ANTES de alvo?"
    
    **3. Assumptions Te√≥ricas**
    - ‚ö†Ô∏è "Alto = ruim" ou "Baixo = ruim" nem sempre
    - ‚úÖ An√°lise distribui√ß√µes emp√≠ricas PRIMEIRO
    - ‚úÖ Testes estat√≠sticos (t-test, Mann-Whitney)
    
    **4. Valida√ß√£o Sint√©tica**
    - ‚ö†Ô∏è Sint√©tico ‚â† valida√ß√£o independente
    - ‚úÖ Sint√©tico = interpola√ß√£o do treino
    - ‚úÖ Test set real = valida√ß√£o autoritativa
    
    **5. Documenta√ß√£o**
    - ‚úÖ Documentar decis√µes (por que CatBoost?)
    - ‚úÖ Manter hist√≥rico falhas (valor aprendizado)
    - ‚úÖ Criar evid√™ncias stakeholders
    
    **6. Limita√ß√µes (NOVO)**
    - ‚úÖ Documentar o que N√ÉO sabemos
    - ‚úÖ Transpar√™ncia > ocultar fraquezas
    - ‚úÖ Roadmap mitiga√ß√£o claro
    """)

st.markdown("---")

# ===== FOOTER =====
st.success("""
üéØ **Resumo Executivo:**

Este projeto demonstra como **desenvolver uma POC de Machine Learning com rigor cient√≠fico** 
mantendo **transpar√™ncia sobre limita√ß√µes**. 

**Principais conquistas:**
- ‚úÖ Modelo CatBoost com 78.6% recall e 84.6% precision
- ‚úÖ 111/114 testes automatizados validando pipeline
- ‚úÖ Documenta√ß√£o extensiva (TEMPORAL_LIMITATIONS, AB_TESTING_GUIDE, MODEL_COMPARISON)
- ‚úÖ Consci√™ncia cient√≠fica sobre impossibilidade causal temporal
- ‚úÖ Roadmap claro para produ√ß√£o (3-4 semanas) e evolu√ß√£o (3-6 meses)

**Diferencial:** N√£o apenas resultados, mas **processo valid√°vel e transparente**.
""")

st.info("""
üìö **Documenta√ß√£o T√©cnica Completa:**

- **TEMPORAL_LIMITATIONS.md** (1000 linhas) - An√°lise limita√ß√µes temporais dataset agregado
- **AB_TESTING_GUIDE.md** (950 linhas) - Guia valida√ß√£o emp√≠rica produ√ß√£o
- **MODEL_COMPARISON.md** - Compara√ß√£o XGBoost vs LightGBM vs CatBoost
- **FEATURE_ENGINEERING_TEMPORAL.md** (850 linhas) - Roadmap features time-series
- **CHANGELOG.md** - Hist√≥rico completo projeto (12 fases desenvolvimento)
- **Notebooks 02B-08** - Implementa√ß√£o t√©cnica detalhada

üí° **Para leitores t√©cnicos:** Consulte documenta√ß√£o .md para detalhes metodol√≥gicos completos.
""")

st.caption("""
---
**Contexto da Pesquisa** | Projeto POC IoT Sensor Failure Prediction | CatBoost v1.0.0  
Leonardo Bora | Est√°gio P&D Lightera | Novembro 2025
""")
