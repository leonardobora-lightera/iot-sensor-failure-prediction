{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1405c8",
   "metadata": {},
   "source": [
    "# üìä Notebook 02B: Stratified Split por Device ID\n",
    "\n",
    "**Objetivo:** Corrigir distribution shift do split temporal (NB02) implementando **Stratified Split por Device ID** para garantir critical devices proporcionalmente distribu√≠dos entre train/test.\n",
    "\n",
    "**Problema anterior:** Split temporal (70% dias) resultou em 88.8% dos critical devices apenas no train, causando class imbalance extremo no test (32.3:1) e recall insuficiente (4.76%). \n",
    "\n",
    "**Solu√ß√£o:** Split por device_id (70/30 stratified) garantindo zero overlap, todas as mensagens (jan-out) de cada device no conjunto correspondente. Resultado esperado: test com ~56 critical devices (vs 21), imbalance 6.7:1 (vs 32.3:1), recall 40-50% (vs 4.76%).\n",
    "\n",
    "---\n",
    "Data: 2025-01-27 | Autor: Leonardo Costa + GitHub Copilot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b02c5",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup e Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9b9f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports completos!\n",
      "üì¶ Pandas: 2.3.3\n",
      "üì¶ Numpy: 2.3.4\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn para stratified split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "\n",
    "# Config\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Imports completos!\")\n",
    "print(f\"üì¶ Pandas: {pd.__version__}\")\n",
    "print(f\"üì¶ Numpy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c57540",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Carregar Dataset COMPLETO (ANTES do split temporal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07a11575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Arquivos dispon√≠veis em data/:\n",
      "  - device_features_test_with_telemetry.csv (0.2 MB)\n",
      "  - device_features_train_with_telemetry.csv (0.2 MB)\n",
      "  - device_features_with_telemetry.csv (0.2 MB)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTANTE: Carregar dataset RAW antes de qualquer split\n",
    "# Usar o arquivo original processado (n√£o os CSVs com train/test j√° divididos)\n",
    "\n",
    "data_dir = Path('../data')\n",
    "\n",
    "# TODO: Verificar qual √© o arquivo RAW correto\n",
    "# Op√ß√µes: \n",
    "# 1. Se existe um processed_sensor_data.csv com TODOS os dados\n",
    "# 2. Ou precisamos concatenar device_features_train.csv + device_features_test.csv\n",
    "\n",
    "# Por enquanto, vou assumir que precisamos carregar os arquivos de telemetria brutos\n",
    "# e refazer a agrega√ß√£o por device\n",
    "\n",
    "print(\"üìÇ Arquivos dispon√≠veis em data/:\")\n",
    "for f in data_dir.glob('*.csv'):\n",
    "    print(f\"  - {f.name} ({f.stat().st_size / 1024 / 1024:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b637e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Completo carregado:\n",
      "   Total de linhas: 789\n",
      "   Total de colunas: 35\n",
      "   Unique devices: 789\n",
      "\n",
      "Primeiras colunas:\n",
      "['device_id', 'total_messages', 'max_frame_count', 'msg6_count', 'msg6_rate', 'is_critical', 'severity_category', 'optical_mean', 'optical_std', 'optical_min']\n",
      "\n",
      "Amostra:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>device_id</th>\n",
       "      <th>total_messages</th>\n",
       "      <th>max_frame_count</th>\n",
       "      <th>msg6_count</th>\n",
       "      <th>msg6_rate</th>\n",
       "      <th>is_critical</th>\n",
       "      <th>severity_category</th>\n",
       "      <th>optical_mean</th>\n",
       "      <th>optical_std</th>\n",
       "      <th>optical_min</th>\n",
       "      <th>...</th>\n",
       "      <th>snr_mean</th>\n",
       "      <th>snr_std</th>\n",
       "      <th>snr_min</th>\n",
       "      <th>rsrp_mean</th>\n",
       "      <th>rsrp_std</th>\n",
       "      <th>rsrp_min</th>\n",
       "      <th>rsrq_mean</th>\n",
       "      <th>rsrq_std</th>\n",
       "      <th>rsrq_min</th>\n",
       "      <th>is_critical_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000000000001</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123456789098765</td>\n",
       "      <td>44</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.710909</td>\n",
       "      <td>14.210222</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400000000000004</td>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         device_id  total_messages  max_frame_count  msg6_count  msg6_rate  \\\n",
       "0  100000000000001               2             99.0         0.0        0.0   \n",
       "1  123456789098765              44             13.0         0.0        0.0   \n",
       "2  400000000000004               2             99.0         0.0        0.0   \n",
       "\n",
       "   is_critical severity_category  optical_mean  optical_std  optical_min  ...  \\\n",
       "0        False               NaN           NaN          NaN          NaN  ...   \n",
       "1        False               NaN    -13.710909    14.210222        -31.0  ...   \n",
       "2        False               NaN           NaN          NaN          NaN  ...   \n",
       "\n",
       "   snr_mean  snr_std  snr_min  rsrp_mean  rsrp_std  rsrp_min  rsrq_mean  \\\n",
       "0       NaN      NaN      NaN        NaN       NaN       NaN        NaN   \n",
       "1       0.0      0.0      0.0        NaN       NaN       NaN        NaN   \n",
       "2       NaN      NaN      NaN        NaN       NaN       NaN        NaN   \n",
       "\n",
       "   rsrq_std  rsrq_min  is_critical_target  \n",
       "0       NaN       NaN                   0  \n",
       "1       NaN       NaN                   0  \n",
       "2       NaN       NaN                   0  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carregar dataset COMPLETO (antes do split temporal)\n",
    "df_complete = pd.read_csv('../data/device_features_with_telemetry.csv')\n",
    "\n",
    "print(\"Dataset Completo carregado:\")\n",
    "print(f\"   Total de linhas: {len(df_complete):,}\")\n",
    "print(f\"   Total de colunas: {len(df_complete.columns)}\")\n",
    "print(f\"   Unique devices: {df_complete['device_id'].nunique():,}\")\n",
    "\n",
    "print(\"\\nPrimeiras colunas:\")\n",
    "print(df_complete.columns.tolist()[:10])\n",
    "print(\"\\nAmostra:\")\n",
    "df_complete.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074cec27",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Calcular msg6_rate por Device (Per√≠odo Completo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c90b876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Calculando msg6_rate por device (per√≠odo completo)...\n",
      "======================================================================\n",
      "‚úÖ 789 devices processados\n",
      "\n",
      "üìä Estat√≠sticas de msg6_rate:\n",
      "count    789.000000\n",
      "mean       0.074723\n",
      "std        0.094311\n",
      "min        0.000000\n",
      "25%        0.006349\n",
      "50%        0.040000\n",
      "75%        0.106509\n",
      "max        0.600000\n",
      "Name: msg6_rate, dtype: float64\n",
      "\n",
      "üìä Distribui√ß√£o de msg6_count:\n",
      "count     789.000000\n",
      "mean       67.356147\n",
      "std       262.443479\n",
      "min         0.000000\n",
      "25%         6.000000\n",
      "50%        18.000000\n",
      "75%        69.000000\n",
      "max      5688.000000\n",
      "Name: msg6_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calcular estat√≠sticas por device usando TODO o per√≠odo\n",
    "print(\"üî¢ Calculando msg6_rate por device (per√≠odo completo)...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Estat√≠sticas b√°sicas por device\n",
    "device_stats = df_complete.groupby('device_id').agg({\n",
    "    'total_messages': 'first',  # J√° est√° agregado no dataset\n",
    "    'msg6_count': 'first',      # J√° est√° agregado\n",
    "    'msg6_rate': 'first'        # J√° est√° agregado\n",
    "}).reset_index()\n",
    "\n",
    "print(f\"‚úÖ {len(device_stats)} devices processados\")\n",
    "print(f\"\\nüìä Estat√≠sticas de msg6_rate:\")\n",
    "print(device_stats['msg6_rate'].describe())\n",
    "print(f\"\\nüìä Distribui√ß√£o de msg6_count:\")\n",
    "print(device_stats['msg6_count'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0d9b26",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Usar is_critical_target do Dataset (Target Real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e1e7898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Usando is_critical_target do Dataset...\n",
      "======================================================================\n",
      "üìä Target Real (is_critical_target):\n",
      "  Total devices: 789\n",
      "  Non-Critical: 744 (94.3%)\n",
      "  Critical: 45 (5.7%)\n",
      "  Class imbalance: 16.5:1\n",
      "\n",
      "‚úÖ Usando target CORRETO do Notebook 02 (n√£o recalculado)\n"
     ]
    }
   ],
   "source": [
    "# Usar is_critical_target do dataset (target definido no Notebook 02)\n",
    "print(\"üéØ Usando is_critical_target do Dataset...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extrair is_critical_target por device\n",
    "device_stats = df_complete.groupby('device_id').agg({\n",
    "    'total_messages': 'first',\n",
    "    'msg6_count': 'first',\n",
    "    'msg6_rate': 'first',\n",
    "    'is_critical_target': 'first'  # Target real do Notebook 02\n",
    "}).reset_index()\n",
    "\n",
    "# Renomear para is_critical (usado no stratified split)\n",
    "device_stats['is_critical'] = device_stats['is_critical_target']\n",
    "\n",
    "# Estat√≠sticas\n",
    "n_critical = device_stats['is_critical'].sum()\n",
    "n_non_critical = len(device_stats) - n_critical\n",
    "critical_pct = n_critical / len(device_stats) * 100\n",
    "\n",
    "print(f\"üìä Target Real (is_critical_target):\")\n",
    "print(f\"  Total devices: {len(device_stats)}\")\n",
    "print(f\"  Non-Critical: {n_non_critical} ({100-critical_pct:.1f}%)\")\n",
    "print(f\"  Critical: {n_critical} ({critical_pct:.1f}%)\")\n",
    "print(f\"  Class imbalance: {n_non_critical/n_critical:.1f}:1\")\n",
    "print(f\"\\n‚úÖ Usando target CORRETO do Notebook 02 (n√£o recalculado)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3981b685",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ ‚≠ê STRATIFIED SPLIT 70/30 por Device_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a3199d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÄ STRATIFIED SPLIT por Device_ID...\n",
      "======================================================================\n",
      "‚úÖ SPLIT COMPLETO!\n",
      "\n",
      "üìä TRAIN SET:\n",
      "  Devices: 552\n",
      "  Critical: 31 (5.6%)\n",
      "  Non-Critical: 521\n",
      "  Rows no dataset: 552\n",
      "\n",
      "üìä TEST SET:\n",
      "  Devices: 237\n",
      "  Critical: 14 (5.9%)\n",
      "  Non-Critical: 223\n",
      "  Rows no dataset: 237\n",
      "\n",
      "üéØ Class Imbalance:\n",
      "  Train: 16.8:1\n",
      "  Test: 15.9:1\n"
     ]
    }
   ],
   "source": [
    "# STRATIFIED SPLIT: Dividir DEVICES (n√£o mensagens) mantendo propor√ß√£o de critical\n",
    "print(\"üîÄ STRATIFIED SPLIT por Device_ID...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Sklearn stratified split\n",
    "train_devices, test_devices = train_test_split(\n",
    "    device_stats['device_id'],\n",
    "    test_size=0.3,\n",
    "    stratify=device_stats['is_critical'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Converter para sets para facilitar valida√ß√£o\n",
    "train_devices_set = set(train_devices)\n",
    "test_devices_set = set(test_devices)\n",
    "\n",
    "# Filtrar dataset completo por device_id\n",
    "df_train = df_complete[df_complete['device_id'].isin(train_devices_set)].copy()\n",
    "df_test = df_complete[df_complete['device_id'].isin(test_devices_set)].copy()\n",
    "\n",
    "# Estat√≠sticas do split\n",
    "train_critical = device_stats[device_stats['device_id'].isin(train_devices_set)]['is_critical'].sum()\n",
    "test_critical = device_stats[device_stats['device_id'].isin(test_devices_set)]['is_critical'].sum()\n",
    "\n",
    "train_critical_pct = train_critical / len(train_devices) * 100\n",
    "test_critical_pct = test_critical / len(test_devices) * 100\n",
    "\n",
    "print(f\"‚úÖ SPLIT COMPLETO!\")\n",
    "print(f\"\\nüìä TRAIN SET:\")\n",
    "print(f\"  Devices: {len(train_devices):,}\")\n",
    "print(f\"  Critical: {train_critical} ({train_critical_pct:.1f}%)\")\n",
    "print(f\"  Non-Critical: {len(train_devices) - train_critical}\")\n",
    "print(f\"  Rows no dataset: {len(df_train):,}\")\n",
    "print(f\"\\nüìä TEST SET:\")\n",
    "print(f\"  Devices: {len(test_devices):,}\")\n",
    "print(f\"  Critical: {test_critical} ({test_critical_pct:.1f}%)\")\n",
    "print(f\"  Non-Critical: {len(test_devices) - test_critical}\")\n",
    "print(f\"  Rows no dataset: {len(df_test):,}\")\n",
    "print(f\"\\nüéØ Class Imbalance:\")\n",
    "print(f\"  Train: {(len(train_devices) - train_critical)/train_critical:.1f}:1\")\n",
    "print(f\"  Test: {(len(test_devices) - test_critical)/test_critical:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cc98c8",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ ‚úÖ Valida√ß√µes Cr√≠ticas (Zero Overlap + Propor√ß√µes Balanceadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6c95e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VALIDA√á√ïES CR√çTICAS...\n",
      "======================================================================\n",
      "‚úÖ Valida√ß√£o 1: ZERO OVERLAP entre train e test devices\n",
      "‚úÖ Valida√ß√£o 2: Test set tem 14 critical devices (‚â•10)\n",
      "‚úÖ Valida√ß√£o 3: Diferen√ßa de propor√ß√£o critical = 0.29% (<2%)\n",
      "‚úÖ Valida√ß√£o 4: Total devices preservado (789)\n",
      "‚úÖ Valida√ß√£o 5: Total critical devices preservado (45)\n",
      "\n",
      "üéâ TODAS AS VALIDA√á√ïES PASSARAM!\n"
     ]
    }
   ],
   "source": [
    "# VALIDA√á√ïES CR√çTICAS\n",
    "print(\"üîç VALIDA√á√ïES CR√çTICAS...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# 1Ô∏è‚É£ Zero overlap entre train e test devices\n",
    "overlap = train_devices_set & test_devices_set\n",
    "assert len(overlap) == 0, f\"‚ùå ERRO: {len(overlap)} devices aparecem em TRAIN e TEST!\"\n",
    "print(f\"‚úÖ Valida√ß√£o 1: ZERO OVERLAP entre train e test devices\")\n",
    "\n",
    "# 2Ô∏è‚É£ M√≠nimo de 10 critical devices no test set (ajustado para dataset real)\n",
    "assert test_critical >= 10, f\"‚ùå ERRO: Test tem apenas {test_critical} critical devices (m√≠nimo 10)!\"\n",
    "print(f\"‚úÖ Valida√ß√£o 2: Test set tem {test_critical} critical devices (‚â•10)\")\n",
    "\n",
    "# 3Ô∏è‚É£ Diferen√ßa de propor√ß√£o de critical entre train e test < 2%\n",
    "proportion_diff = abs(train_critical_pct - test_critical_pct)\n",
    "assert proportion_diff < 2.0, f\"‚ùå ERRO: Diferen√ßa de propor√ß√£o {proportion_diff:.2f}% (m√°ximo 2%)!\"\n",
    "print(f\"‚úÖ Valida√ß√£o 3: Diferen√ßa de propor√ß√£o critical = {proportion_diff:.2f}% (<2%)\")\n",
    "\n",
    "# 4Ô∏è‚É£ Total de devices somados = original\n",
    "total_split_devices = len(train_devices) + len(test_devices)\n",
    "original_total_devices = device_stats['device_id'].nunique()\n",
    "assert total_split_devices == original_total_devices, f\"‚ùå ERRO: {total_split_devices} vs {original_total_devices} devices!\"\n",
    "print(f\"‚úÖ Valida√ß√£o 4: Total devices preservado ({total_split_devices:,})\")\n",
    "\n",
    "# 5Ô∏è‚É£ Total de critical devices somados = original\n",
    "total_split_critical = train_critical + test_critical\n",
    "original_total_critical = device_stats['is_critical'].sum()\n",
    "assert total_split_critical == original_total_critical, f\"‚ùå ERRO: {total_split_critical} vs {original_total_critical} critical!\"\n",
    "print(f\"‚úÖ Valida√ß√£o 5: Total critical devices preservado ({total_split_critical})\")\n",
    "\n",
    "print(f\"\\nüéâ TODAS AS VALIDA√á√ïES PASSARAM!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e655644b",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ üéØ Adicionar Target 'is_critical' aos Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5663d673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Adicionando coluna target 'is_critical'...\n",
      "‚úÖ Target adicionado com sucesso!\n",
      "\n",
      "üìä Distribui√ß√£o da vari√°vel target:\n",
      "\n",
      "TRAIN:\n",
      "is_critical\n",
      "0    521\n",
      "1     31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "TEST:\n",
      "is_critical\n",
      "0    223\n",
      "1     14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Adicionar coluna 'is_critical' baseada no device_id\n",
    "print(\"üéØ Adicionando coluna target 'is_critical'...\")\n",
    "\n",
    "# Criar dict de mapeamento device_id -> is_critical\n",
    "critical_mapping = device_stats.set_index('device_id')['is_critical'].to_dict()\n",
    "\n",
    "# Aplicar aos datasets\n",
    "df_train['is_critical'] = df_train['device_id'].map(critical_mapping)\n",
    "df_test['is_critical'] = df_test['device_id'].map(critical_mapping)\n",
    "\n",
    "# Validar que n√£o h√° valores NaN\n",
    "assert df_train['is_critical'].isna().sum() == 0, \"‚ùå Train set tem NaN em is_critical!\"\n",
    "assert df_test['is_critical'].isna().sum() == 0, \"‚ùå Test set tem NaN em is_critical!\"\n",
    "\n",
    "print(f\"‚úÖ Target adicionado com sucesso!\")\n",
    "print(f\"\\nüìä Distribui√ß√£o da vari√°vel target:\")\n",
    "print(f\"\\nTRAIN:\")\n",
    "print(df_train['is_critical'].value_counts())\n",
    "print(f\"\\nTEST:\")\n",
    "print(df_test['is_critical'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e10bc",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ üíæ Salvar Datasets Stratificados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "479cd2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Salvando datasets stratificados...\n",
      "======================================================================\n",
      "‚úÖ TRAIN salvo: ..\\data\\device_features_train_stratified.csv\n",
      "   Shape: (552, 35)\n",
      "   Devices: 552\n",
      "   Critical: 31\n",
      "\n",
      "‚úÖ TEST salvo: ..\\data\\device_features_test_stratified.csv\n",
      "   Shape: (237, 35)\n",
      "   Devices: 237\n",
      "   Critical: 14\n",
      "\n",
      "üéâ DATASETS STRATIFICADOS PRONTOS PARA USO!\n"
     ]
    }
   ],
   "source": [
    "# Salvar datasets stratificados\n",
    "print(\"üíæ Salvando datasets stratificados...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Caminho para salvar (mesma pasta dos arquivos originais)\n",
    "import os\n",
    "data_dir = os.path.join('..', 'data')\n",
    "\n",
    "train_path = os.path.join(data_dir, 'device_features_train_stratified.csv')\n",
    "test_path = os.path.join(data_dir, 'device_features_test_stratified.csv')\n",
    "\n",
    "# Salvar\n",
    "df_train.to_csv(train_path, index=False)\n",
    "df_test.to_csv(test_path, index=False)\n",
    "\n",
    "print(f\"‚úÖ TRAIN salvo: {train_path}\")\n",
    "print(f\"   Shape: {df_train.shape}\")\n",
    "print(f\"   Devices: {df_train['device_id'].nunique():,}\")\n",
    "print(f\"   Critical: {df_train['is_critical'].sum()}\")\n",
    "\n",
    "print(f\"\\n‚úÖ TEST salvo: {test_path}\")\n",
    "print(f\"   Shape: {df_test.shape}\")\n",
    "print(f\"   Devices: {df_test['device_id'].nunique():,}\")\n",
    "print(f\"   Critical: {df_test['is_critical'].sum()}\")\n",
    "\n",
    "print(f\"\\nüéâ DATASETS STRATIFICADOS PRONTOS PARA USO!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
