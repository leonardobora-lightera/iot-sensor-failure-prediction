# ğŸ“Š IoT Critical Device Prediction - Notebooks# ğŸ“Š IoT Critical Device Prediction - Notebooks



## ğŸ¯ Objetivo## ğŸ¯ Objetivo

Prever dispositivos IoT crÃ­ticos (falhas de comunicaÃ§Ã£o) baseado em padrÃµes de telemetria, status e anomalias.Prever dispositivos IoT crÃ­ticos (falhas de comunicaÃ§Ã£o) baseado em padrÃµes de telemetria, status e anomalias.



------



## âš ï¸ TRANSIÃ‡ÃƒO PARA MODELO V2 (13/Nov/2025)## âš ï¸ TRANSIÃ‡ÃƒO PARA MODELO V2 (13/Nov/2025)



Este projeto passou por uma **refatoraÃ§Ã£o importante** para eliminar contaminaÃ§Ã£o de dados FACTORY (lab testing):Este projeto passou por uma **refatoraÃ§Ã£o importante** para eliminar contaminaÃ§Ã£o de dados FACTORY (lab testing):



### ğŸ“Œ Modelo v1 (ARQUIVADO)### ğŸ“Œ Modelo v1 (ARQUIVADO)

- **Dataset:** Mixed FACTORY+FIELD (789 devices)- **Dataset:** Mixed FACTORY+FIELD (789 devices)

- **Performance:** Recall 78.6%, Precision 84.6%, AUC 0.8621- **Performance:** Recall 78.6%, Precision 84.6%, AUC 0.8621

- **Problema:** Lifecycle mixing (lab + production data juntos)- **Problema:** Lifecycle mixing (lab + production data juntos)

- **Notebooks:** Movidos para `archive_v1/` (preservados para referÃªncia)- **Notebooks:** Movidos para `archive_v1/` (preservados para referÃªncia)



### âœ… Modelo v2 (ATUAL)### âœ… Modelo v2 (ATUAL)

- **Dataset:** FIELD-only (762 devices, 30 features)- **Dataset:** FIELD-only (762 devices, 30 features)

- **Filtro:** `MODE='FIELD'` - removidos 362k mensagens FACTORY (31.8%)- **Filtro:** `MODE='FIELD'` - removidos 362k mensagens FACTORY (31.8%)

- **Nova feature:** `days_since_last_message` (detecta devices inativos)- **Nova feature:** `days_since_last_message` (detecta devices inativos)

- **Performance:** Recall 57.1%, Precision 57.1%, **AUC 0.9186** (+6.6%)- **Performance:** Recall 57.1%, Precision 57.1%, **AUC 0.9186** (+6.6%)

- **Trade-off:** -21.5% recall, mas **fundaÃ§Ã£o limpa** para melhorias futuras- **Trade-off:** -21.5% recall, mas **fundaÃ§Ã£o limpa** para melhorias futuras

- **Filosofia:** "2 passos atrÃ¡s, 3 pra frente"- **Filosofia:** "2 passos atrÃ¡s, 3 pra frente"



### ğŸš€ PrÃ³ximos Passos (Roadmap v2)### ğŸš€ PrÃ³ximos Passos (Roadmap v2)

1. **Hyperparameter Tuning:** GridSearch CatBoost (esperado +10-15% recall)1. **Hyperparameter Tuning:** GridSearch CatBoost (esperado +10-15% recall)

2. **Feature Engineering Temporal:** Adicionar 4 features (FASE 3, 2 semanas)2. **Feature Engineering Temporal:** Adicionar 4 features (FASE 3, 2 semanas)

3. **Threshold Calibration:** Otimizar decision boundary3. **Threshold Calibration:** Otimizar decision boundary



------



## ğŸ“ Estrutura Atual## ğŸ“ Estrutura de Notebooks v2



### Notebooks Ativos (v2)**NOTA:** Notebooks v1 (02B-08) foram movidos para `archive_v1/` para preservar histÃ³rico.

**NOTA:** Novos notebooks v2 serÃ£o criados sob demanda:

- `09_model_v2_field_only.ipynb` - Treinamento e anÃ¡lise modelo v2 (planejado)Novos notebooks v2 serÃ£o criados sob demanda:

- `10_temporal_features.ipynb` - ImplementaÃ§Ã£o features FASE 3 (planejado)- `09_model_v2_field_only.ipynb` - Treinamento e anÃ¡lise modelo v2

- `11_hyperparameter_tuning.ipynb` - OtimizaÃ§Ã£o GridSearch (planejado)- `10_temporal_features.ipynb` - ImplementaÃ§Ã£o features FASE 3

- `11_hyperparameter_tuning.ipynb` - OtimizaÃ§Ã£o GridSearch

### Notebooks Arquivados (v1)

Ver `archive_v1/` para notebooks do modelo v1 (mixed FACTORY+FIELD data):---



- **02B_stratified_split_by_device.ipynb** - Split estratificado 70/30 (789 devices)## ğŸ“š Notebooks Arquivados (v1)

- **02_correlacao_telemetrias_msg6.ipynb** - AnÃ¡lise correlaÃ§Ãµes telemetrias

- **03_status_modelagem_pratica.ipynb** - Baseline com Dropna## ğŸ“š Notebooks Arquivados (v1)

- **04B_sem_leakage_LIMPO.ipynb** - Baseline com Imputation (29 features)

- **04_correcao_class_imbalance.ipynb** - CorreÃ§Ã£o class imbalanceVer `archive_v1/` para notebooks do modelo v1 (mixed FACTORY+FIELD data):

- **05_smote_optimization.ipynb** - OtimizaÃ§Ã£o SMOTE 0.5

- **06B_synthetic_validation_empirical.ipynb** - ValidaÃ§Ã£o dados sintÃ©ticos### **02B_stratified_split_by_device.ipynb** âš ï¸ v1

- **06_synthetic_data_validation.ipynb** - ValidaÃ§Ã£o dados sintÃ©ticos**FunÃ§Ã£o:** GeraÃ§Ã£o de Dados com Split Estratificado (789 devices)  

- **07_model_optimization.ipynb** - ComparaÃ§Ã£o XGBoost/LightGBM/CatBoost**Status:** ARQUIVADO - Dataset sem filtro MODE

- **08_pipeline_producao.ipynb** - Pipeline v1 final (DEPRECATED - contaminated with FACTORY data)

### **03_status_modelagem_pratica.ipynb** âš ï¸ v1

---**FunÃ§Ã£o:** Baseline com Dropna  

**Status:** ARQUIVADO - Baseline funcional mas limitado

## ğŸ”§ Pipeline de Treinamento v2- `dropna()` reduz amostras crÃ­ticas:

  - Train: 31 â†’ **13 critical** (perda de 58%)

```  - Test: 14 â†’ **7 critical** (perda de 50%)

payloads_lora_final.csv (2.04 GB, 1,138,275 messages)- MÃ©tricas baseadas em **apenas 7 samples** (baixa confianÃ§a estatÃ­stica)

                    â†“

     [MODE='FIELD' Filter] â†’ Remove 362k FACTORY (31.8%)**Valor:**

                    â†“- Prova de conceito: Split estratificado funciona (0% recall no temporal â†’ 85.71%)

     [Aggregate by Device] â†’ 30 features (29 + days_since_last_message)- Baseline simples para comparaÃ§Ã£o

                    â†“

device_features_with_telemetry_field_only.csv (762 devices, 46 critical)---

                    â†“

     [Stratified Split 70/30]### **04B_sem_leakage_LIMPO.ipynb** ğŸŒŸ

                    â†“**FunÃ§Ã£o:** Baseline REAL com Imputation (SEM Data Leakage)  

         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”**Status:** âœ… ATIVO - Baseline vÃ¡lido para produÃ§Ã£o  

         â†“                     â†“

    TRAIN (533)            TEST (229)**O que faz:**

   32 critical           14 critical- Carrega CSVs estratificados

         â†“                     â†“- **Identifica e REMOVE features com data leakage** (`msg6_count`, `msg6_rate`)

     [SimpleImputer â†’ SMOTE 0.5 â†’ CatBoost]- Aplica `SimpleImputer(strategy='median')` preservando **TODOS** os 31 train + 14 test critical

         â†“- Treina RandomForest com `class_weight='balanced'` em **29 features limpas**

    Recall: 57.1% (8/14)- Executa **4 validaÃ§Ãµes rigorosas** confirmando leakage removido

    Precision: 57.1%

    AUC: 0.9186**Resultados REAIS (Test Set):**

``````

Recall:            50.00% (7 de 14 critical detectados)

---Precision:         87.50% (1 falso positivo)

F1-Score:          63.64%

## ğŸ“ ReferÃªnciasBalanced Accuracy: 74.78%

ROC-AUC:           0.9065

- **CÃ³digo Treinamento v2:** `train_model_v2.py` (script Python standalone)```

- **Processamento Payloads:** `process_payloads_chunks.py` + `scripts/transform_aws_payload.py`

- **Modelo v2:** `models/catboost_pipeline_v2_field_only.pkl` (127.9 KB)**Por que as mÃ©tricas "caÃ­ram"?**

- **Metadata v2:** `models/catboost_pipeline_v2_metadata.json`

- **Plano de AÃ§Ã£o:** `docs/PLANO_ACAO_FIX_FALSOS_POSITIVOS.md`| MÃ©trica | NB03 (dropna) | NB04B (REAL) | AnÃ¡lise |

- **Feature Engineering:** `docs/FEATURE_ENGINEERING_TEMPORAL.md` (roadmap FASE 3)|---------|---------------|--------------|---------|

| Recall | 85.71% | **50.00%** | 6/7 vs 7/14 samples - mais confiÃ¡vel |

---| Precision | 100.00% | **87.50%** | Artificial vs realista |

| Samples | 7 critical | **14 critical** | 2x mais dados |

## ğŸ“ LiÃ§Ãµes Aprendidas

**Descoberta CrÃ­tica:**

### Por que v2 tem recall menor?- Notebook inicial (04_OLD) tinha **precision 100%, AUC 0.9994** â†’ "Bom demais para ser verdade?"

1. **Dataset menor:** 789 â†’ 762 devices (-3.4%)- ValidaÃ§Ã£o revelou **DATA LEAKAGE**: Features `msg6_rate` (42.1% importance) e `msg6_count` (5.8%) estavam vazando a **definiÃ§Ã£o do target**

2. **Menos "informative noise":** FACTORY tinha padrÃµes de degradaÃ§Ã£o (mesmo sendo lab)- Target: `is_critical_target = (msg6_count > IQR_threshold)`

3. **Pipeline mais rigoroso:** Production-only elimina lifecycle mixing- Modelo aprendia: "Se msg6_rate > X â†’ Critical" (circular, inÃºtil)



### Por que AUC melhorou?**CorreÃ§Ã£o:**

- **0.8621 â†’ 0.9186 (+6.6%)** indica melhor **ranking/calibraÃ§Ã£o**- Removidas **2 features contaminadas**: `msg6_count`, `msg6_rate`

- Modelo sabe ORDENAR probabilidades melhor (mesmo errando threshold)- Preservadas **29 features legÃ­timas**: telemetria (optical, temp, battery, SNR, RSRP), status, agregaÃ§Ãµes

- FundaÃ§Ã£o sÃ³lida para hyperparameter tuning- Modelo agora aprende padrÃµes REAIS: anomalias de telemetria + volume de mensagens + conectividade



### Trade-off validado**ValidaÃ§Ãµes (4/4 Aprovadas):**

- âœ… "2 passos atrÃ¡s, 3 pra frente"1. âœ… Zero features `msg6_*` ou `msg_type_6_*`

- âœ… Recall recuperÃ¡vel com GridSearch + features temporais2. âœ… AUC 0.9065 < 0.98 (threshold sklearn para leakage)

- âœ… Dados limpos > dados contaminados3. âœ… Top feature `max_frame_count` 29.5% < 40% (distribuÃ­do, nÃ£o dominante)

- âœ… AUC alto = confianÃ§a em probabilidades4. âœ… Precision 87.5% < 100% (erros normais, nÃ£o artificial)



---**Features Importantes (Top 5):**

1. `max_frame_count` (29.5%): Picos anormais de frames

**Ãšltima atualizaÃ§Ã£o:** 13/Nov/2025 - Leonardo Costa2. `total_messages` (16.5%): Volume de comunicaÃ§Ãµes

3. `optical_readings` (15.6%): Leituras Ã³pticas totais
4. `temp_mean` (5.7%): Temperatura mÃ©dia
5. `rsrp_mean` (2.3%): Sinal de conectividade

**Threshold Condicional:**
- âœ… **Recall 50.0% â‰¥ 30%** â†’ **SMOTE ELEGÃVEL**
- Modelo tem poder preditivo REAL baseado em padrÃµes legÃ­timos
- PrÃ³ximo passo: OtimizaÃ§Ã£o com SMOTE (esperado recall 60-70%)

---

## ğŸš€ Pipeline de Desenvolvimento

```
device_features_with_telemetry.csv (789 devices, 45 critical)
                    â†“
     [02B] Stratified Split por device_id
                    â†“
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â†“                     â†“
    TRAIN (552)            TEST (237)
   31 critical           14 critical
         â†“                     â†“
     [03] Baseline Dropna (REFERÃŠNCIA)
         â†“
    13 critical â†’ 85.71% recall (6/7 samples)
    âš ï¸ Limitado: apenas 7 test samples
         â†“
     [04B] Baseline LIMPO (ATIVO)
         â†“
    31 critical â†’ 50.0% recall (7/14 samples)
    âœ… REAL: 14 test samples, sem leakage
         â†“
    [05] SMOTE Optimization (PRÃ“XIMO)
         â†“
    Target: 60-70% recall, 80%+ precision
```

---

## ğŸ“Š Resultados Chave

### **ComparaÃ§Ã£o Evolutiva:**

| Split | Train/Test | Critical | Recall | Precision | Problema |
|-------|------------|----------|--------|-----------|----------|
| **Temporal** | 750/689 | 187/42 | **0%** | - | Leakage (650 overlap) |
| **Estratificado + Dropna** | 552/237 | 13/7 | **85.71%** | 100% | Poucos samples (7) |
| **Estratificado + Leakage** | 552/237 | 31/14 | 85.71% | 100% | Features vazam target |
| **Estratificado + LIMPO** | 552/237 | 31/14 | **50.0%** | 87.5% | âœ… **VÃLIDO** |

### **Ganho Real:**
- Split Temporal: **0% recall** (nÃ£o detecta NENHUM critical)
- Baseline Atual: **50% recall** (detecta 7 de 14 critical)
- **Melhoria:** 0% â†’ 50% = **INFINITO** ğŸ¯

---

## ğŸ“ Notebooks HistÃ³ricos (old/)

### **04_OLD_com_leakage.ipynb**
- Baseline com **DATA LEAKAGE** (precision 100%, AUC 0.9994)
- **Preservado** como documentaÃ§Ã£o histÃ³rica da descoberta
- Features `msg6_rate` (42.1%) e `msg6_count` (5.8%) dominavam
- Modelo aprendia **definiÃ§Ã£o do target**, nÃ£o padrÃµes

### **02_correlacao_telemetrias_msg6.ipynb**
- EDA de correlaÃ§Ãµes entre telemetrias e msg6_count
- **Preservado** como referÃªncia de anÃ¡lise exploratÃ³ria
- Ãštil para entender relaÃ§Ãµes entre features

---

## ğŸ¯ PrÃ³ximos Passos

### **1. SMOTE Optimization (Notebook 05)**
**Status:** ELEGÃVEL (recall 50% â‰¥ 30%)  
**Objetivo:** Aumentar recall para 60-70% mantendo precision 80%+

**EstratÃ©gia:**
- Testar `sampling_strategy`: 0.3, 0.5, 0.7
- Comparar RandomForest + SMOTE vs XGBoost + SMOTE
- ValidaÃ§Ã£o com 3-fold CV para estabilidade

**Expectativa:**
- Recall: 50% â†’ **60-70%** (+10-20%)
- Precision: 87.5% â†’ **80-85%** (tolerÃ¡vel para recall gain)
- DetecÃ§Ã£o: 7/14 â†’ **8-10/14** devices crÃ­ticos

---

### **2. Model Comparison (Notebook 06)**
**Status:** CONDICIONAL (se recall â‰¥60%)  
**Modelos:** RF+SMOTE, XGBoost, LightGBM, Ensemble

---

### **3. Production Pipeline (Notebook 08)**
**Deliverables:**
- Pipeline sklearn (imputation â†’ SMOTE â†’ model)
- Modelo treinado (joblib)
- FunÃ§Ã£o de inferÃªncia
- DocumentaÃ§Ã£o executiva

---

## ğŸ’¡ LiÃ§Ãµes Aprendidas

### âœ… **1. Sempre Questionar MÃ©tricas Perfeitas**
- Precision 100% com class imbalance 16.8:1 era **estatisticamente improvÃ¡vel**
- ValidaÃ§Ã£o rigorosa revelou data leakage antes de produÃ§Ã£o

### âœ… **2. ValidaÃ§Ã£o Multi-Ã‚ngulo**
- AUC 0.9994 (threshold sklearn â‰¥0.98)
- Feature importance 42.1% (dominÃ¢ncia anormal)
- Correlation 0.69 (muito alta)
- Probability distribution (separaÃ§Ã£o perfeita)

### âœ… **3. MÃ©tricas que Caem Podem Ser CorreÃ§Ãµes**
- Recall 85.71% â†’ 50% parece piora
- MAS: 85.71% era **artificial** (leakage), 50% Ã© **REAL** (vÃ¡lido)
- Stakeholders precisam entender: drops sÃ£o **honestos**, nÃ£o falhas

### âœ… **4. Split Estratificado > Temporal**
- Dataset agregado (1 row/device) nÃ£o Ã© time-series
- Split temporal causou overlap (650 devices) e distribution shift
- Split estratificado por device: zero overlap, generalizaÃ§Ã£o vÃ¡lida

### âœ… **5. Imputation > Dropna**
- Dropna: 31 â†’ 13 critical (perda 58%)
- Imputation: 31 â†’ 31 critical (preservaÃ§Ã£o 100%)
- Mais dados â†’ MÃ©tricas mais confiÃ¡veis

---

## ğŸ“š DocumentaÃ§Ã£o Adicional

- **LEAKAGE_DISCOVERY.md**: AnÃ¡lise completa da descoberta de data leakage (timeline, evidÃªncias, correÃ§Ã£o, liÃ§Ãµes)
- **CHANGELOG.md**: Timeline evolutiva do projeto (6 fases)
- **TODO.md**: Lista de tarefas e progresso

---

## ğŸ”§ DependÃªncias

**Python Packages:**
- pandas
- scikit-learn
- scipy
- matplotlib
- seaborn
- imbalanced-learn (SMOTE)

**Data Files:**
- `device_features_with_telemetry.csv` (fonte)
- `device_features_train_stratified.csv` (gerado por 02B)
- `device_features_test_stratified.csv` (gerado por 02B)

---

## ğŸ‘¥ Stakeholder Summary

**Objetivo:** Detectar dispositivos IoT crÃ­ticos antes de falha total  

**Abordagem:** Machine learning baseado em **padrÃµes de similaridade** (nÃ£o previsÃ£o temporal)

**Resultados Atuais:**
- âœ… **50% de recall** (7 de 14 devices crÃ­ticos detectados)
- âœ… **87.5% de precision** (1 alarme falso em 237 testes)
- âœ… Modelo **vÃ¡lido e confiÃ¡vel** (data leakage corrigido)

**Valor de NegÃ³cio:**
- Split temporal: **0% detecÃ§Ã£o** â†’ **Falha total**
- Baseline atual: **50% detecÃ§Ã£o** â†’ **Melhoria infinita**
- Com SMOTE: **60-70% detecÃ§Ã£o** esperada â†’ **8-10 falhas prevenidas de 14**

**PrÃ³ximos 30 dias:**
- OtimizaÃ§Ã£o SMOTE (Semana 2)
- ComparaÃ§Ã£o de modelos (Semana 3)
- Pipeline produÃ§Ã£o (Semana 4)

---

**Ãšltima AtualizaÃ§Ã£o:** 6 de Novembro de 2025  
**Status do Projeto:** âœ… Baseline vÃ¡lido estabelecido, pronto para otimizaÃ§Ã£o
